{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import  Image\n",
    "import pandas\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parent directory is: c:\\Users\\kkosara\\ImageAutoEncoder\n"
     ]
    }
   ],
   "source": [
    "parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(\"The parent directory is:\", parent_directory)\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data import get_image_data\n",
    "from Models import encoder_model, decoder_model, VAE, load_model_vae\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    \"used to sample a vector in latent space with learned mean - z_mean and (log) variance - z_log_var\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        vec_len = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch_size, vec_len))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Define the encoder model\n",
    "def encoder_model_gs(input_shape, filters, dense_layer_dim, latent_dim):\n",
    "    \"\"\"\n",
    "    Creates an encoder model for grayscale images that maps input images to a lower-dimensional latent space.\n",
    "    \n",
    "    Args:\n",
    "    - input_shape: Tuple representing the shape of the input images (height, width, channels).\n",
    "    - filters: List of integers representing the number of filters in each convolutional layer.\n",
    "    - dense_layer_dim: Integer representing the number of neurons in the dense layer.\n",
    "    - latent_dim: Integer representing the dimensionality of the latent space.\n",
    "    \n",
    "    Returns:\n",
    "    - encoder: Keras Model object representing the encoder model.\n",
    "    - encoder_layers_dim: List of tuples representing the dimensionality of each layer in the encoder.\n",
    "    \"\"\"\n",
    "    # Create input layer\n",
    "    encoder_layers_dim = []  # List to store the dimensions of each layer in the encoder\n",
    "    \n",
    "    # Define the input layer\n",
    "    encoder_inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoder_layers_dim.append(tuple(encoder_inputs.shape[1:]))  # Add input layer dimensions to list\n",
    "    \n",
    "    # Add convolutional layers with specified number of filters and activation function\n",
    "    x = layers.Conv2D(filters[0], (3,3), activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "    encoder_layers_dim.append(tuple(x.shape[1:]))  # Add conv layer dimensions to list\n",
    "    x = BatchNormalization()(x)\n",
    "    # Add additional convolutional layers with specified number of filters and activation function\n",
    "    mid_layers = [layers.Conv2D(f, 3, activation=\"relu\", strides=2, padding=\"same\") for f in filters[1:]]\n",
    "    for mid_layer in mid_layers:\n",
    "        x = mid_layer(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        encoder_layers_dim.append(tuple(x.shape[1:]))  # Add mid layer dimensions to list\n",
    "    \n",
    "    # Flatten convolutional output to prepare for dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    encoder_layers_dim.append(tuple(x.shape[1:]))  # Add flattened layer dimensions to list\n",
    "    \n",
    "    # Add dense layer with specified number of neurons and activation function\n",
    "    x = layers.Dense(dense_layer_dim, activation='relu')(x)\n",
    "    \n",
    "    # Add output layers for latent space (mean and variance) and sample from this space\n",
    "    z_mean = layers.Dense(latent_dim, name = \"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder_layers_dim.append(tuple(z.shape[1:]))  # Add output layer dimensions to list\n",
    "    \n",
    "    # Create encoder model\n",
    "    return tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder'), encoder_layers_dim\n",
    "\n",
    "# decoder model for grayscale images\n",
    "def decoder_model_gs(encoder_layers_dim):\n",
    "    # Extract necessary dimensions from encoder model output\n",
    "    latent_dim = encoder_layers_dim[-1][0]\n",
    "    dense_layer_dim = encoder_layers_dim[-2][0]\n",
    "    first_conv_layer_dim = encoder_layers_dim[-3]\n",
    "    output_layer = encoder_layers_dim[0]\n",
    "\n",
    "    # Create input layer for latent space vector\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "\n",
    "    # Determine number of filters for each transpose convolutional layer\n",
    "    filters = [f[-1] for f in encoder_layers_dim[1:-2]]\n",
    "\n",
    "    # Feed latent vector through a dense layer with ReLU activation\n",
    "    # Note that we apply the first filter in the form of dense and reshape it\n",
    "    x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Dense(dense_layer_dim, activation=\"relu\")(x)\n",
    "    x = layers.Reshape(first_conv_layer_dim)(x)\n",
    "\n",
    "    # Apply series of transpose convolutional layers with ReLU activation and same padding and Upsampling\n",
    "    mid_layers = [layers.Conv2DTranspose(f, 3, activation=\"relu\", strides=2, padding=\"same\") for f in filters[::-1]]\n",
    "    for mid_layer in mid_layers:\n",
    "        x = mid_layer(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    # Apply final convolutional layer with sigmoid activation to output reconstructed image\n",
    "    decoder_outputs = layers.Conv2DTranspose(output_layer[-1], 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Create and return Keras model with latent vector as input and reconstructed image as output\n",
    "    return tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    # Compute the negative SSIM between y_true and y_pred\n",
    "    ssim = tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "    loss = 1.0 - ssim\n",
    "    return loss\n",
    "\n",
    "# VAE for GrayScale Images\n",
    "class VAE_RBG(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    This is a Variational Autoencoder (VAE) implemented using the Keras Model API. It has an encoder and a decoder network defined separately and passed to the constructor as arguments. The VAE class inherits from the Keras Model class and overrides the train_step() method to define the training loop.\n",
    "\n",
    "    During forward pass, the encoder takes an input image and outputs the mean and standard deviation of a latent space distribution, as well as a sampled vector from that distribution. The decoder takes the sampled vector and outputs a reconstructed image.\n",
    "\n",
    "    The training loop consists of computing the reconstruction loss and the KL divergence loss, and then computing gradients and updating weights using the Adam optimizer. The reconstruction loss measures the difference between the input image and the reconstructed image, while the KL divergence loss measures the divergence between the latent space distribution and a standard normal distribution. The total loss is the sum of the two losses.\n",
    "\n",
    "    The VAE class also defines three metrics to track during training: the total loss, the reconstruction loss, and the KL divergence loss. These metrics are updated in the train_step() method and can be accessed via the metrics property. The train_step() method returns a dictionary of these metrics.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # Define metrics to track during training\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    # Define forward pass\n",
    "    def call(self, x):\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return z_mean, z_log_var, z, reconstruction\n",
    "\n",
    "    # Define training step\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass through encoder and decoder\n",
    "            z_mean, z_log_var, z, reconstruction = self(data)\n",
    "            \n",
    "            # Compute reconstruction loss\n",
    "            #tf.keras.losses.MeanAbsoluteError()\n",
    "            # tf.keras.losses.MeanSquaredError()\n",
    "            reconstruction_loss = tf.reduce_mean(tf.keras.losses.MeanAbsoluteError()(data, reconstruction))\n",
    "            # ssim = tf.image.ssim(data, reconstruction, max_val=1.0)\n",
    "            # reconstruction_loss = 1.0 - ssim\n",
    "            # Compute KL divergence loss\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            # Compute total loss\n",
    "            total_loss = reconstruction_loss + 1e5*kl_loss\n",
    "            \n",
    "        # Compute gradients and update weights\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # Return metrics as dictionary\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "class VAECallbackRGB(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, vae, test_dataset, n=10):\n",
    "        self.vae = vae\n",
    "        self.test_dataset = test_dataset\n",
    "        self.n = n\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Generate decoded images from the test input\n",
    "        test_batch = next(iter(self.test_dataset))\n",
    "        _, _, _, reconstructed_images = self.vae.predict(test_batch)\n",
    "\n",
    "        # Rescale pixel values to [0, 1]\n",
    "        reconstructed_images = np.clip(reconstructed_images, 0.0, 1.0)\n",
    "\n",
    "        # Plot the original and reconstructed images side by side\n",
    "        plt.figure(figsize=(10, 20))\n",
    "        for i in range(self.n):\n",
    "            plt.subplot(10, 2, 2*i+1)\n",
    "            plt.imshow(test_batch[i])\n",
    "            plt.axis('off')\n",
    "            plt.subplot(10, 2, 2*i+2)\n",
    "            plt.imshow(reconstructed_images[i])\n",
    "            plt.axis('off')\n",
    "        plt.savefig('decoded_images_epoch_{:04d}.png'.format(epoch))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\kkosara\\\\eight_30_hz\n",
      "Total number of imges: 155135\n",
      "(56, 56, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The directory path where your image data is stored\n",
    "# all_dirs = ['/home/kkosara/AutoDRIVE-Nigel-Dataset/fishhook_30_hz', '/home/kkosara/AutoDRIVE-Nigel-Dataset/skidpad_30_hz', '/home/kkosara/AutoDRIVE-Nigel-Dataset/slalom_30_hz']\n",
    "DATA_DIR =  [r'C:\\\\Users\\\\kkosara\\\\eight_30_hz'] # C:\\Users\\kkosara\\eight_30_hz\n",
    "OUTPUT_IMAGE_SHAPE = 56\n",
    "INPUT_SHAPE = (OUTPUT_IMAGE_SHAPE, OUTPUT_IMAGE_SHAPE, 3)\n",
    "FILTERS = [32, 64]\n",
    "NUM_CONV_LAYERS = len(FILTERS)\n",
    "DENSE_LAYER_DIM = 16\n",
    "LATENT_DIM = 20\n",
    "BETA = 1.0\n",
    "BATCH_SIZE = 128\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 10\n",
    "EPOCHS  = 2\n",
    "TRAIN_SPLIT = 0.8\n",
    "LOGDIR = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "GRAYSCALE = True\n",
    "\n",
    "# all_image_paths = get_image_data(DATA_DIR)\n",
    "# image_count = len(all_image_paths)\n",
    "\n",
    "# Create a dataset from the list of image file paths\n",
    "all_image_paths = get_image_data(DATA_DIR)\n",
    "image_count = len(all_image_paths)\n",
    "\n",
    "# Create a dataset from the list of image file paths\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "\n",
    "# Shuffle the dataset with a buffer size of 1000 and seed of 42\n",
    "dataset = dataset.shuffle(buffer_size=1000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "# Load and preprocess the images\n",
    "def load_and_preprocess_image(path, shape=(OUTPUT_IMAGE_SHAPE, OUTPUT_IMAGE_SHAPE)):\n",
    "    # Load the image file\n",
    "    image = tf.io.read_file(path)\n",
    "    # Decode the image to a tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    image = tf.image.resize(image, shape)\n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "dataset = dataset.map(load_and_preprocess_image)\n",
    "for image in dataset.take(5):\n",
    "    image_np = image.numpy() # convert to a NumPy array\n",
    "    print(image.shape)\n",
    "    # create a PIL Image object from the NumPy array\n",
    "    pil_image = Image.fromarray(np.uint8(image_np*255))\n",
    "    # Display the image using Matplotlib\n",
    "    # plt.imshow(image_np, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plot the image using matplotlib\n",
    "    plt.imshow(pil_image)\n",
    "    plt.show()\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset = dataset.take(int(TRAIN_SPLIT * image_count))\n",
    "val_dataset = dataset.take(int((1-TRAIN_SPLIT) * image_count))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=500, seed=42)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=500, seed=42)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.shuffle(buffer_size=500, seed=42)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 56, 56, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 32)   896         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 64)   18496       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 14, 14, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 12544)        0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16)           200720      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 20)           340         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 20)           340         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_4 (Sampling)           (None, 20)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 221,176\n",
      "Trainable params: 220,984\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "[(56, 56, 3), (28, 28, 32), (14, 14, 64), (12544,), (20,)]\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12544)             213248    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 56, 56, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 56, 56, 3)         867       \n",
      "=================================================================\n",
      "Total params: 270,227\n",
      "Trainable params: 270,035\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder, encoder_layers_dim = encoder_model_gs(input_shape = INPUT_SHAPE, filters=FILTERS, dense_layer_dim=DENSE_LAYER_DIM, latent_dim=LATENT_DIM)\n",
    "print(encoder.summary())\n",
    "print(encoder_layers_dim)\n",
    "decoder = decoder_model_gs(encoder_layers_dim)\n",
    "print(decoder.summary())\n",
    "vae = VAE_RBG(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "684/970 [====================>.........] - ETA: 18s - loss: 46.6831 - reconstruction_loss: 0.1014 - kl_loss: 7.3126e-05"
     ]
    }
   ],
   "source": [
    "vae_callback = VAECallbackRGB(vae, val_dataset)\n",
    "\n",
    "history = vae.fit(train_dataset, epochs=300, callbacks=[vae_callback])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_baseline_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
